{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cf1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium .common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d270d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid argument provided to the WebDriver.\n",
      "Message: invalid argument: invalid locator\n",
      "  (Session info: chrome=123.0.6312.106)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF603197072+63090]\n",
      "\t(No symbol) [0x00007FF603102CC2]\n",
      "\t(No symbol) [0x00007FF602F9EC65]\n",
      "\t(No symbol) [0x00007FF602FE486C]\n",
      "\t(No symbol) [0x00007FF602FE4ADC]\n",
      "\t(No symbol) [0x00007FF603025B37]\n",
      "\t(No symbol) [0x00007FF60300701F]\n",
      "\t(No symbol) [0x00007FF603023412]\n",
      "\t(No symbol) [0x00007FF603006D83]\n",
      "\t(No symbol) [0x00007FF602FD83A8]\n",
      "\t(No symbol) [0x00007FF602FD9441]\n",
      "\tGetHandleVerifier [0x00007FF6035925CD+4238285]\n",
      "\tGetHandleVerifier [0x00007FF6035CF72D+4488493]\n",
      "\tGetHandleVerifier [0x00007FF6035C7A0F+4456463]\n",
      "\tGetHandleVerifier [0x00007FF6032705B6+953270]\n",
      "\t(No symbol) [0x00007FF60310E58F]\n",
      "\t(No symbol) [0x00007FF603109264]\n",
      "\t(No symbol) [0x00007FF60310939B]\n",
      "\t(No symbol) [0x00007FF6030F9BD4]\n",
      "\tBaseThreadInitThunk [0x00007FFA1073257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFA1218AA58+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Que 1\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import InvalidArgumentException, NoSuchElementException\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    table = driver.find_element('//*[@id=\"mw-content-text\"]/div[1]/table[3]')\n",
    "\n",
    "    \n",
    "    ranks = []\n",
    "    names = []\n",
    "    artists = []\n",
    "    upload_dates = []\n",
    "    views = []\n",
    "\n",
    "\n",
    "    for row in table.find_elements(\".//tr\")[1:]:\n",
    "        try:\n",
    "            \n",
    "            rank = row.find_element_by_xpath(\".//td[1]\").text\n",
    "            name = row.find_element_by_xpath(\".//td[2]\").text\n",
    "            artist = row.find_element_by_xpath(\".//td[3]\").text\n",
    "            upload_date = row.find_element_by_xpath(\".//td[4]\").text\n",
    "            view = row.find_element_by_xpath(\".//td[5]\").text\n",
    "\n",
    "        \n",
    "            ranks.append(rank)\n",
    "            names.append(name)\n",
    "            artists.append(artist)\n",
    "            upload_dates.append(upload_date)\n",
    "            views.append(view)\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            pass  \n",
    "\n",
    "    for i in range(len(ranks)):\n",
    "        print(f\"Rank: {ranks[i]}, Name: {names[i]}, Artist: {artists[i]}, Upload Date: {upload_dates[i]}, Views: {views[i]}\")\n",
    "\n",
    "except InvalidArgumentException as e:\n",
    "    print(\"Invalid argument provided to the WebDriver.\")\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c7bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que 2\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://www.bcci.tv/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    international_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"international-dropdown\"]/button')))\n",
    "    international_button.click()\n",
    "\n",
    "    fixtures_link = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, '//*[@id=\"international-dropdown\"]/div/ul/li[1]/a')))\n",
    "    fixtures_link.click()\n",
    "\n",
    "    series = []\n",
    "    places = []\n",
    "    dates = []\n",
    "    times = []\n",
    "\n",
    "    fixtures_list = driver.find_elements_by_xpath('//*[@id=\"fixture__latest-tab-content\"]/div/div/div/a')\n",
    "\n",
    "    \n",
    "    for fixture in fixtures_list:\n",
    "\n",
    "        series_name = fixture.find_element_by_class_name('fixture__name').text\n",
    "        place = fixture.find_element_by_class_name('fixture__info').text\n",
    "        date = fixture.find_element_by_class_name('fixture__date').text\n",
    "        time = fixture.find_element_by_class_name('fixture__time').text\n",
    "\n",
    "        series.append(series_name)\n",
    "        places.append(place)\n",
    "        dates.append(date)\n",
    "        times.append(time)\n",
    "\n",
    "\n",
    "    for i in range(len(series)):\n",
    "        print(f\"Series: {series[i]}, Place: {places[i]}, Date: {dates[i]}, Time: {times[i]}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4c975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que 3\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "\n",
    "    url = \"http://statisticstimes.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    economy_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/button')))\n",
    "    economy_link.click()\n",
    "\n",
    "    gdp_states_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')))\n",
    "    gdp_states_link.click()\n",
    "\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"table_id\"]/tbody/tr[1]/td[1]')))\n",
    "\n",
    "\n",
    "    ranks = []\n",
    "    states = []\n",
    "    gsdp_18_19 = []\n",
    "    gsdp_19_20 = []\n",
    "    share_18_19 = []\n",
    "    gdp_billion = []\n",
    "\n",
    "    rows = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        rank = row.find_element_by_xpath(\"./td[1]\").text\n",
    "        state = row.find_element_by_xpath(\"./td[2]\").text\n",
    "        gsdp_18_19_val = row.find_element_by_xpath(\"./td[3]\").text\n",
    "        gsdp_19_20_val = row.find_element_by_xpath(\"./td[4]\").text\n",
    "        share_18_19_val = row.find_element_by_xpath(\"./td[5]\").text\n",
    "        gdp_billion_val = row.find_element_by_xpath(\"./td[6]\").text\n",
    "\n",
    "        ranks.append(rank)\n",
    "        states.append(state)\n",
    "        gsdp_18_19.append(gsdp_18_19_val)\n",
    "        gsdp_19_20.append(gsdp_19_20_val)\n",
    "        share_18_19.append(share_18_19_val)\n",
    "        gdp_billion.append(gdp_billion_val)\n",
    "\n",
    "    for i in range(len(ranks)):\n",
    "        print(f\"Rank: {ranks[i]}, State: {states[i]}, GSDP(18-19): {gsdp_18_19[i]}, GSDP(19-20): {gsdp_19_20[i]}, \"\n",
    "              f\"Share(18-19): {share_18_19[i]}, GDP($ billion): {gdp_billion[i]}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705db7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que4\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    \n",
    "    url = \"https://github.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    \n",
    "    explore_menu = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"header\"]/div[1]/div/div[2]/nav/ul/li[4]/details/summary')))\n",
    "    explore_menu.click()\n",
    "\n",
    "    trending_option = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"header\"]/div[1]/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a')))\n",
    "    trending_option.click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article')))\n",
    "\n",
    "    repositories = driver.find_elements_by_xpath('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article')\n",
    "\n",
    "    for repo in repositories:\n",
    "        title = repo.find_element_by_xpath(\".//h1/a\").text.strip()\n",
    "        description = repo.find_element_by_xpath(\".//p\").text.strip()\n",
    "        contributors_count = repo.find_element_by_xpath(\".//div/a[2]\").text.strip()\n",
    "        language_used = repo.find_element_by_xpath(\".//div/span/span\").text.strip()\n",
    "\n",
    "        print(f\"Repository Title: {title}\")\n",
    "        print(f\"Repository Description: {description}\")\n",
    "        print(f\"Contributors Count: {contributors_count}\")\n",
    "        print(f\"Language Used: {language_used}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e13b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que5\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    url = \"https://www.billboard.com/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    charts_menu = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/div[1]/header/div/ul/li[3]/a')))\n",
    "    charts_menu.click()\n",
    "    \n",
    "    hot_100_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"root\"]/div[1]/header/div/ul/li[3]/div/ul/li[1]/a')))\n",
    "    hot_100_link.click()\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"charts\"]/div/div[7]/div/ol/li[1]')))\n",
    "\n",
    "    song_names = []\n",
    "    artist_names = []\n",
    "    last_week_ranks = []\n",
    "    peak_ranks = []\n",
    "    weeks_on_board = []\n",
    "\n",
    "    songs = driver.find_elements_by_xpath('//*[@id=\"charts\"]/div/div[7]/div/ol/li')\n",
    "\n",
    "    for song in songs:\n",
    "        song_name = song.find_element_by_xpath(\".//button/span[2]\").text.strip()\n",
    "        artist_name = song.find_element_by_xpath(\".//button/span[3]\").text.strip()\n",
    "        last_week_rank = song.find_element_by_xpath(\".//button/div[1]\").text.strip()\n",
    "        peak_rank = song.find_element_by_xpath(\".//button/div[2]\").text.strip()\n",
    "        weeks_on_board = song.find_element_by_xpath(\".//button/div[3]\").text.strip()\n",
    "\n",
    "        song_names.append(song_name)\n",
    "        artist_names.append(artist_name)\n",
    "        last_week_ranks.append(last_week_rank)\n",
    "        peak_ranks.append(peak_rank)\n",
    "        weeks_on_board.append(weeks_on_board)\n",
    "\n",
    "    for i in range(10): \n",
    "        print(f\"Song Name: {song_names[i]}\")\n",
    "        print(f\"Artist Name: {artist_names[i]}\")\n",
    "        print(f\"Last Week Rank: {last_week_ranks[i]}\")\n",
    "        print(f\"Peak Rank: {peak_ranks[i]}\")\n",
    "        print(f\"Weeks on Board: {weeks_on_board[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21099ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: invalid argument: invalid locator\n",
      "  (Session info: chrome=123.0.6312.106)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF603197072+63090]\n",
      "\t(No symbol) [0x00007FF603102CC2]\n",
      "\t(No symbol) [0x00007FF602F9EC65]\n",
      "\t(No symbol) [0x00007FF602FE486C]\n",
      "\t(No symbol) [0x00007FF602FE4ADC]\n",
      "\t(No symbol) [0x00007FF603025B67]\n",
      "\t(No symbol) [0x00007FF60300701F]\n",
      "\t(No symbol) [0x00007FF603023412]\n",
      "\t(No symbol) [0x00007FF603006D83]\n",
      "\t(No symbol) [0x00007FF602FD83A8]\n",
      "\t(No symbol) [0x00007FF602FD9441]\n",
      "\tGetHandleVerifier [0x00007FF6035925CD+4238285]\n",
      "\tGetHandleVerifier [0x00007FF6035CF72D+4488493]\n",
      "\tGetHandleVerifier [0x00007FF6035C7A0F+4456463]\n",
      "\tGetHandleVerifier [0x00007FF6032705B6+953270]\n",
      "\t(No symbol) [0x00007FF60310E58F]\n",
      "\t(No symbol) [0x00007FF603109264]\n",
      "\t(No symbol) [0x00007FF60310939B]\n",
      "\t(No symbol) [0x00007FF6030F9BD4]\n",
      "\tBaseThreadInitThunk [0x00007FFA1073257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFA1218AA58+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Que6 \n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "    driver.get(url)\n",
    "\n",
    "    book_names = []\n",
    "    author_names = []\n",
    "    volumes_sold = []\n",
    "    publishers = []\n",
    "    genres = []\n",
    "\n",
    "    rows = driver.find_elements('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr')\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            book_name = row.find_element(\"./td[2]\").text\n",
    "        except NoSuchElementException:\n",
    "            book_name = \"\"\n",
    "        \n",
    "        try:\n",
    "            author_name = row.find_element(\"./td[3]\").text\n",
    "        except NoSuchElementException:\n",
    "            author_name = \"\"\n",
    "        \n",
    "        try:\n",
    "            volume_sold = row.find_element(\"./td[4]\").text\n",
    "        except NoSuchElementException:\n",
    "            volume_sold = \"\"\n",
    "        \n",
    "        try:\n",
    "            publisher = row.find_element(\"./td[5]\").text\n",
    "        except NoSuchElementException:\n",
    "            publisher = \"\"\n",
    "        \n",
    "        try:\n",
    "            genre = row.find_element(\"./td[6]\").text\n",
    "        except NoSuchElementException:\n",
    "            genre = \"\"\n",
    "\n",
    "        book_names.append(book_name)\n",
    "        author_names.append(author_name)\n",
    "        volumes_sold.append(volume_sold)\n",
    "        publishers.append(publisher)\n",
    "        genres.append(genre)\n",
    "\n",
    "    for i in range(len(book_names)):\n",
    "        print(f\"Book Name: {book_names[i]}\")\n",
    "        print(f\"Author Name: {author_names[i]}\")\n",
    "        print(f\"Volumes Sold: {volumes_sold[i]}\")\n",
    "        print(f\"Publisher: {publishers[i]}\")\n",
    "        print(f\"Genre: {genres[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ab879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que 7\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"lister-item-content\")))\n",
    "\n",
    "    names = []\n",
    "    year_spans = []\n",
    "    genres = []\n",
    "    run_times = []\n",
    "    ratings = []\n",
    "    votes = []\n",
    "\n",
    "    tv_series = driver.find_elements_by_class_name(\"lister-item-content\")\n",
    "    for series in tv_series:\n",
    "        name = series.find_element_by_xpath(\".//h3/a\").text.strip()\n",
    "        year_span = series.find_element_by_xpath(\".//span[@class='lister-item-year text-muted unbold']\").text.strip()\n",
    "        genre = series.find_element_by_xpath(\".//span[@class='genre']\").text.strip()\n",
    "        run_time = series.find_element_by_xpath(\".//span[@class='runtime']\").text.strip()\n",
    "        rating = series.find_element_by_xpath(\".//span[@class='ipl-rating-star__rating']\").text.strip()\n",
    "        vote = series.find_element_by_xpath(\".//span[@name='nv']\").text.strip().replace(\",\", \"\")\n",
    "\n",
    "        names.append(name)\n",
    "        year_spans.append(year_span)\n",
    "        genres.append(genre)\n",
    "        run_times.append(run_time)\n",
    "        ratings.append(rating)\n",
    "        votes.append(vote)\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        print(f\"Name: {names[i]}\")\n",
    "        print(f\"Year Span: {year_spans[i]}\")\n",
    "        print(f\"Genre: {genres[i]}\")\n",
    "        print(f\"Run Time: {run_times[i]}\")\n",
    "        print(f\"Ratings: {ratings[i]}\")\n",
    "        print(f\"Votes: {votes[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d719654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout occurred while waiting for elements to load.\n"
     ]
    }
   ],
   "source": [
    "#Que 8\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    url = \"https://archive.ics.uci.edu/\"\n",
    "    driver.get(url)\n",
    "\n",
    "    view_all_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '/html/body/table[1]/tbody/tr/td[2]/span[2]/a[1]')))\n",
    "    view_all_link.click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '/html/body/table[2]/tbody/tr/td[2]/table[2]')))\n",
    "\n",
    "    dataset_names = []\n",
    "    data_types = []\n",
    "    tasks = []\n",
    "    attribute_types = []\n",
    "    instances = []\n",
    "    attributes = []\n",
    "    years = []\n",
    "\n",
    "    rows = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr')\n",
    "    for row in rows[1:]:\n",
    "        columns = row.find_elements_by_tag_name('td')\n",
    "        dataset_names.append(columns[0].text)\n",
    "        data_types.append(columns[1].text)\n",
    "        tasks.append(columns[2].text)\n",
    "        attribute_types.append(columns[3].text)\n",
    "        instances.append(columns[4].text)\n",
    "        attributes.append(columns[5].text)\n",
    "        years.append(columns[6].text)\n",
    "\n",
    "    for i in range(len(dataset_names)):\n",
    "        print(f\"Dataset Name: {dataset_names[i]}\")\n",
    "        print(f\"Data Type: {data_types[i]}\")\n",
    "        print(f\"Task: {tasks[i]}\")\n",
    "        print(f\"Attribute Type: {attribute_types[i]}\")\n",
    "        print(f\"No of Instances: {instances[i]}\")\n",
    "        print(f\"No of Attributes: {attributes[i]}\")\n",
    "        print(f\"Year: {years[i]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for elements to load.\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befed6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
