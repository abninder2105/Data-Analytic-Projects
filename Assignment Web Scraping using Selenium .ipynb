{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba23f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f14d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For designation we are providing the input\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3047461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For clicking the search button\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361064de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for location filter\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[3]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[4]/div[2]/div[2]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe307ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the job titles \n",
    "job_title = []\n",
    "count = 0\n",
    "title_tag = driver.find_elements(By.XPATH,'//div[@class=\" row1\"]/a')\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "    count+= 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(job_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838868b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the value of job location\n",
    "job_location = []\n",
    "count = 0\n",
    "location_tag = driver.find_elements(By.XPATH, '//span[@class=\"loc-wrap ver-line\"]')\n",
    "for i in location_tag:\n",
    "    job_location.append(i.text)\n",
    "    count+= 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(job_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "count = 0\n",
    "company_tag = driver.find_elements(By.XPATH, '//a[@class=\" comp-name mw-25\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "    count+= 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(company_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = []\n",
    "count =  0\n",
    "exp_tag = driver.find_elements(By.XPATH, '//span[@class=\"exp-wrap\"]')\n",
    "for i in exp_tag:\n",
    "    experience.append(i.text)\n",
    "    count+= 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Title\": job_title, \"Company\": company_name, \"Location\":job_location, \"Experience\": experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb60a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que 2\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dde16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME, \"form-control  \" )\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae560546",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input ')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For clicking the search button\n",
    "search = driver.find_element(By.XPATH, \"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "count = 0\n",
    "job_tag = driver.find_elements(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[1]/div/div[1]/a')\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaaa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "count = 0\n",
    "company_tag = driver.find_elements(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[1]/div/div[2]/span/a[1]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "    count+= 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = []\n",
    "count = 0\n",
    "exp_tag = driver.find_elements(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[2]/div/div[3]/div/span[1]/span/span')\n",
    "for i in exp_tag:\n",
    "    exp.append(i.text)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326786af",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_loc = []\n",
    "count= 0\n",
    "loation_tag = driver.find_elements(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[2]/div/div[3]/div/span[3]/span' )\n",
    "for i in loc_tag:\n",
    "    job_loc.append(i.text)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break\n",
    "        \n",
    "print(job_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b81931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Titles\": job_title, \"Location\": job_loc, \n",
    "                   \"Company Name\":company_name, \"Experience\": exp})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que 3\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-15-black-128-gb/p/itm6ac6485515ae4?pid=MOBGTAGPTB3VS24W&lid=LSTMOBGTAGPTB3VS24WVZNSC6&marketplace=FLIPKART&q=iphone+15&store=tyy/4io&srno=s_1_2&otracker=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_2_na_na_na&fm=organic&iid=b596c120-8114-44e8-9819-0b4dee130fa9.MOBGTAGPTB3VS24W.SEARCH&ppt=hp&ppn=homepage&ssid=s3c8i7dsvk0000001710403029549&qH=2f54b45b321e3ae5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating= []\n",
    "count = 0\n",
    "rating_tag = driver.find_elements(By.CLASS_NAME, \"_3LWZlK _1BLPMq\")\n",
    "for i in rating_tag:\n",
    "    rating.append(i.text)\n",
    "    count+=1\n",
    "    if count == 100:\n",
    "        break\n",
    "\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db578842",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sum = []\n",
    "count = 0\n",
    "sum_tag = driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[3]/div/div/div[2]/div[3]/div/div/div/div[1]/p\")\n",
    "for i in sum_tag:\n",
    "    review_sum.append(i.text)\n",
    "    count+=1\n",
    "    if count == 100:\n",
    "        break\n",
    "    \n",
    "print(review_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300be6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sum= []\n",
    "count = 0\n",
    "fullsum_tag= driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[3]/div/div/div[2]/div[6]/div/div/div/div[2]/div/div/div\")\n",
    "for i in fullsum_tag:\n",
    "    full_sum.append(i.text)\n",
    "    count+=1\n",
    "    if count == 100:\n",
    "        break\n",
    "\n",
    "print(full_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Rating\":rating, \n",
    "\"Review Smummary\": review_sum, \"Summary\":full_sum})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc469a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que 4 \n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Flipkart and search for sneakers\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "\n",
    "# Close the login popup if it appears\n",
    "try:\n",
    "    driver.find_elements(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "search_bar = driver.find_elements(\"//input[@title='Search for products, brands and more']\")\n",
    "search_bar.send_keys(\"sneakers\")\n",
    "search_bar.submit()\n",
    "\n",
    "\n",
    "# Scroll down to load more products (if needed)\n",
    "for _ in range(5):  # Adjust the range as needed\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "\n",
    "# Find all the products on the page\n",
    "products = driver.find_elements_by_xpath(\"//div[@class='_1AtVbE']\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "\n",
    "# Loop through each product and extract data\n",
    "for product in products[:100]:  # Limiting to the first 100 products\n",
    "    brand = product.find_element_by_xpath(\".//div[@class='_2WkVRV']\").text.strip()\n",
    "    description = product.find_element_by_xpath(\".//a[@class='IRpwTa']\").text.strip()\n",
    "    price = product.find_element_by_xpath(\".//div[@class='_30jeq3']\").text.strip()\n",
    "\n",
    "    brands.append(brand)\n",
    "    descriptions.append(description)\n",
    "    prices.append(price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the scraped data\n",
    "for i in range(len(brands)):\n",
    "    print(f\"Product {i+1}:\")\n",
    "    print(f\"Brand: {brands[i]}\")\n",
    "    print(f\"Description: {descriptions[i]}\")\n",
    "    print(f\"Price: {prices[i]}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#que 5\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open Amazon and search for laptops\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "search_bar = driver.find_elements(\"twotabsearchtextbox\")\n",
    "search_bar.send_keys(\"Laptop\")\n",
    "search_bar.submit()\n",
    "\n",
    "# Apply CPU Type filter\n",
    "cpu_filter = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//li[@aria-label='Intel Core i7']\")))\n",
    "cpu_filter.click()\n",
    "\n",
    "# Wait for the results to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@data-component-type='s-search-result']\")))\n",
    "\n",
    "# Get the laptops' data\n",
    "laptops = driver.find_elements(\"//div[@data-component-type='s-search-result']\")[:10]\n",
    "\n",
    "# Initialize lists to store data\n",
    "titles = []\n",
    "ratings = []\n",
    "prices = []\n",
    "\n",
    "# Loop through each laptop and extract data\n",
    "for laptop in laptops:\n",
    "    title = laptop.find_element_by_xpath(\".//span[@class='a-size-medium a-color-base a-text-normal']\").text\n",
    "    rating = laptop.find_element_by_xpath(\".//span[@class='a-icon-alt']\").get_attribute('innerHTML')\n",
    "    price = laptop.find_element_by_xpath(\".//span[@class='a-price-whole']\").text\n",
    "\n",
    "    titles.append(title)\n",
    "    ratings.append(rating)\n",
    "    prices.append(price)\n",
    "\n",
    "\n",
    "# Print the scraped data\n",
    "for i in range(len(titles)):\n",
    "    print(f\"Laptop {i+1}:\")\n",
    "    print(f\"Title: {titles[i]}\")\n",
    "    print(f\"Ratings: {ratings[i]}\")\n",
    "    print(f\"Price: â‚¹{prices[i]}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#que 6\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open azquotes.com\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "# Click on \"Top Quote\"\n",
    "top_quote_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[@title='Top Quote']\")))\n",
    "top_quote_link.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@id='quotesList']\")))\n",
    "\n",
    "# Initialize lists to store data\n",
    "quotes = []\n",
    "authors = []\n",
    "types = []\n",
    "\n",
    "# Scrape data for the Top 1000 Quotes\n",
    "for i in range(1, 11):  # Assuming each page has 100 quotes, so scrape 10 pages for 1000 quotes\n",
    "    # Get all the quotes on the page\n",
    "    quotes_on_page = driver.find_elements_by_xpath(\"//div[@id='quotesList']/div[@class='wrap-block']\")\n",
    "\n",
    "    for quote in quotes_on_page:\n",
    "        # Extract quote, author, and type\n",
    "        quote_text = quote.find_element_by_xpath(\".//a[@class='title js-action-copy-quote']\").text\n",
    "        author_name = quote.find_element_by_xpath(\".//span[@class='author']/a\").text\n",
    "        quote_type = quote.find_element_by_xpath(\".//div[@class='qti-gnre']/a\").text\n",
    "\n",
    "        quotes.append(quote_text)\n",
    "        authors.append(author_name)\n",
    "        types.append(quote_type)\n",
    "\n",
    "    # Go to the next page if available\n",
    "    next_button = driver.find_element_by_xpath(\"//div[@class='box pager-box']/a[@rel='next']\")\n",
    "    if next_button:\n",
    "        next_button.click()\n",
    "        # Wait for the next page to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@id='quotesList']\")))\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print the scraped data\n",
    "for i in range(len(quotes)):\n",
    "    print(f\"Quote {i+1}:\")\n",
    "    print(f\"Quote: {quotes[i]}\")\n",
    "    print(f\"Author: {authors[i]}\")\n",
    "    print(f\"Type: {types[i]}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#que 7\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the URL\n",
    "driver.get(\"https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\")\n",
    "\n",
    "# Wait for the page to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"article-body\")))\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element_by_xpath(\"//table[@class='table']\")\n",
    "rows = table.find_elements_by_xpath(\".//tr\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "names = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remarks = []\n",
    "\n",
    "# Loop through each row in the table (excluding header)\n",
    "for row in rows[1:]:\n",
    "    # Extract data from each column in the row\n",
    "    columns = row.find_elements_by_xpath(\".//td\")\n",
    "    names.append(columns[0].text)\n",
    "    born_dead.append(columns[1].text)\n",
    "    term_of_office.append(columns[2].text)\n",
    "    remarks.append(columns[3].text)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Name\": names,\n",
    "    \"Born-Dead\": born_dead,\n",
    "    \"Term of Office\": term_of_office,\n",
    "    \"Remarks\": remarks\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86250e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que 8\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the motor1.com website\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "# Find the search bar and type '50 most expensive cars'\n",
    "search_bar = driver.find_elements(\"query\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")\n",
    "search_bar.submit()\n",
    "\n",
    "# Click on the search result for '50 most expensive cars in the world'\n",
    "driver.find_elements(\"50 Most Expensive Cars in the World\").click()\n",
    "\n",
    "# Wait for the page to load\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"article-content\")))\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element_by_xpath(\"//table[@class='comparison-table table-dark-theme table-desktop']\")\n",
    "rows = table.find_elements_by_xpath(\".//tr\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "car_names = []\n",
    "prices = []\n",
    "\n",
    "# Loop through each row in the table (excluding header)\n",
    "for row in rows[1:]:\n",
    "    # Extract data from each column in the row\n",
    "    columns = row.find_elements_by_xpath(\".//td\")\n",
    "    car_name = columns[1].text\n",
    "    price = columns[2].text\n",
    "\n",
    "    car_names.append(car_name)\n",
    "    prices.append(price)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Car Name\": car_names,\n",
    "    \"Price\": prices\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df058ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
